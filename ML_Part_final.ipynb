{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "nGtVStKtv6LT",
    "outputId": "500f07cd-2f74-4ae5-8fce-1df0ba4565bc"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i6aZ0NykBT70",
    "outputId": "134978d1-3f04-456d-d08e-d382ba6e0629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "1swM4U97IAeK",
    "outputId": "d745b67b-6e68-43be-efa1-9feeea9c7551"
   },
   "outputs": [],
   "source": [
    "weights = load_pretrained_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VggVox(weights=weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUQYaOUjwjGb"
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "best_loss = torch.autograd.Variable(torch.tensor(np.inf)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bh80WU4lJAxE"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, _, optimizer = load_saved_model(\"checkpoint_20181211-030043_0.014894404448568821.pth.tar\", test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lIKadKjFDTgx",
    "outputId": "6f187bdb-e63d-4e9b-d20f-b5d67cea8a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training unique users 80\n",
      "training samples 12800\n",
      "batches 200\n"
     ]
    }
   ],
   "source": [
    "voxceleb_dataset = VoxCelebDataset(PAIRS_FILE)\n",
    "train_dataloader = DataLoader(voxceleb_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                              num_workers=4)\n",
    "n_batches = int(len(voxceleb_dataset) / BATCH_SIZE)\n",
    "\n",
    "print(\"training unique users\", len(voxceleb_dataset.training_users))\n",
    "print(\"training samples\", len(voxceleb_dataset))\n",
    "print(\"batches\", int(len(voxceleb_dataset) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3519
    },
    "colab_type": "code",
    "id": "FbWVd_VNIVYr",
    "outputId": "9b55d499-8dcf-4f54-80de-f208b94acdd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10  Batch 20/400 \n",
      "Current Batch Loss 0.6339170336723328\n",
      "\n",
      "Epoch 1/10  Batch 40/400 \n",
      "Current Batch Loss 0.8288595080375671\n",
      "\n",
      "Epoch 1/10  Batch 60/400 \n",
      "Current Batch Loss 0.7820997834205627\n",
      "\n",
      "Epoch 1/10  Batch 80/400 \n",
      "Current Batch Loss 0.9524711966514587\n",
      "\n",
      "Epoch 1/10  Batch 100/400 \n",
      "Current Batch Loss 0.7632725238800049\n",
      "\n",
      "Epoch 1/10  Batch 120/400 \n",
      "Current Batch Loss 0.457506388425827\n",
      "\n",
      "Epoch 1/10  Batch 140/400 \n",
      "Current Batch Loss 0.8156790137290955\n",
      "\n",
      "Epoch 1/10  Batch 160/400 \n",
      "Current Batch Loss 0.49526798725128174\n",
      "\n",
      "Epoch 1/10  Batch 180/400 \n",
      "Current Batch Loss 0.8071795701980591\n",
      "\n",
      "Epoch 1/10  Batch 200/400 \n",
      "Current Batch Loss 0.5311578512191772\n",
      "\n",
      "Epoch 1/10  Batch 220/400 \n",
      "Current Batch Loss 0.8559224009513855\n",
      "\n",
      "Epoch 1/10  Batch 240/400 \n",
      "Current Batch Loss 0.46079546213150024\n",
      "\n",
      "Epoch 1/10  Batch 260/400 \n",
      "Current Batch Loss 0.8578991293907166\n",
      "\n",
      "Epoch 1/10  Batch 280/400 \n",
      "Current Batch Loss 0.520740807056427\n",
      "\n",
      "Epoch 1/10  Batch 300/400 \n",
      "Current Batch Loss 0.5934733152389526\n",
      "\n",
      "Epoch 1/10  Batch 320/400 \n",
      "Current Batch Loss 0.6375675797462463\n",
      "\n",
      "Epoch 1/10  Batch 340/400 \n",
      "Current Batch Loss 0.5636889338493347\n",
      "\n",
      "Epoch 1/10  Batch 360/400 \n",
      "Current Batch Loss 0.6397614479064941\n",
      "\n",
      "Epoch 1/10  Batch 380/400 \n",
      "Current Batch Loss 0.722661554813385\n",
      "\n",
      "Epoch 1/10  Batch 400/400 \n",
      "Current Batch Loss 0.5275805592536926\n",
      "\n",
      "==> Epoch 1/10 Epoch Loss 0.022606944665312767\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 2/10  Batch 20/400 \n",
      "Current Batch Loss 0.560128390789032\n",
      "\n",
      "Epoch 2/10  Batch 40/400 \n",
      "Current Batch Loss 0.7130985260009766\n",
      "\n",
      "Epoch 2/10  Batch 60/400 \n",
      "Current Batch Loss 0.32527434825897217\n",
      "\n",
      "Epoch 2/10  Batch 80/400 \n",
      "Current Batch Loss 0.5896878838539124\n",
      "\n",
      "Epoch 2/10  Batch 100/400 \n",
      "Current Batch Loss 0.7818465828895569\n",
      "\n",
      "Epoch 2/10  Batch 120/400 \n",
      "Current Batch Loss 0.5907962322235107\n",
      "\n",
      "Epoch 2/10  Batch 140/400 \n",
      "Current Batch Loss 0.7022435665130615\n",
      "\n",
      "Epoch 2/10  Batch 160/400 \n",
      "Current Batch Loss 0.3824286162853241\n",
      "\n",
      "Epoch 2/10  Batch 180/400 \n",
      "Current Batch Loss 0.45234256982803345\n",
      "\n",
      "Epoch 2/10  Batch 200/400 \n",
      "Current Batch Loss 0.5628209114074707\n",
      "\n",
      "Epoch 2/10  Batch 220/400 \n",
      "Current Batch Loss 0.9481287598609924\n",
      "\n",
      "Epoch 2/10  Batch 240/400 \n",
      "Current Batch Loss 0.504779040813446\n",
      "\n",
      "Epoch 2/10  Batch 260/400 \n",
      "Current Batch Loss 0.42734843492507935\n",
      "\n",
      "Epoch 2/10  Batch 280/400 \n",
      "Current Batch Loss 0.5206369757652283\n",
      "\n",
      "Epoch 2/10  Batch 300/400 \n",
      "Current Batch Loss 0.45342716574668884\n",
      "\n",
      "Epoch 2/10  Batch 320/400 \n",
      "Current Batch Loss 0.38496634364128113\n",
      "\n",
      "Epoch 2/10  Batch 340/400 \n",
      "Current Batch Loss 0.4229603707790375\n",
      "\n",
      "Epoch 2/10  Batch 360/400 \n",
      "Current Batch Loss 0.44211798906326294\n",
      "\n",
      "Epoch 2/10  Batch 380/400 \n",
      "Current Batch Loss 0.46994853019714355\n",
      "\n",
      "Epoch 2/10  Batch 400/400 \n",
      "Current Batch Loss 0.5926098823547363\n",
      "\n",
      "==> Epoch 2/10 Epoch Loss 0.016438601538538933\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 3/10  Batch 20/400 \n",
      "Current Batch Loss 0.36448371410369873\n",
      "\n",
      "Epoch 3/10  Batch 40/400 \n",
      "Current Batch Loss 0.47654232382774353\n",
      "\n",
      "Epoch 3/10  Batch 60/400 \n",
      "Current Batch Loss 0.4014342129230499\n",
      "\n",
      "Epoch 3/10  Batch 80/400 \n",
      "Current Batch Loss 0.6678623557090759\n",
      "\n",
      "Epoch 3/10  Batch 100/400 \n",
      "Current Batch Loss 0.1823909729719162\n",
      "\n",
      "Epoch 3/10  Batch 120/400 \n",
      "Current Batch Loss 0.4790689945220947\n",
      "\n",
      "Epoch 3/10  Batch 140/400 \n",
      "Current Batch Loss 0.44527071714401245\n",
      "\n",
      "Epoch 3/10  Batch 160/400 \n",
      "Current Batch Loss 0.18623904883861542\n",
      "\n",
      "Epoch 3/10  Batch 180/400 \n",
      "Current Batch Loss 0.3141222298145294\n",
      "\n",
      "Epoch 3/10  Batch 200/400 \n",
      "Current Batch Loss 0.3520655333995819\n",
      "\n",
      "Epoch 3/10  Batch 220/400 \n",
      "Current Batch Loss 0.3186463415622711\n",
      "\n",
      "Epoch 3/10  Batch 240/400 \n",
      "Current Batch Loss 0.4248736798763275\n",
      "\n",
      "Epoch 3/10  Batch 260/400 \n",
      "Current Batch Loss 0.3551676571369171\n",
      "\n",
      "Epoch 3/10  Batch 280/400 \n",
      "Current Batch Loss 0.17759697139263153\n",
      "\n",
      "Epoch 3/10  Batch 300/400 \n",
      "Current Batch Loss 0.48830610513687134\n",
      "\n",
      "Epoch 3/10  Batch 320/400 \n",
      "Current Batch Loss 0.45733529329299927\n",
      "\n",
      "Epoch 3/10  Batch 340/400 \n",
      "Current Batch Loss 0.5508818030357361\n",
      "\n",
      "Epoch 3/10  Batch 360/400 \n",
      "Current Batch Loss 0.31420159339904785\n",
      "\n",
      "Epoch 3/10  Batch 380/400 \n",
      "Current Batch Loss 0.1640762835741043\n",
      "\n",
      "Epoch 3/10  Batch 400/400 \n",
      "Current Batch Loss 0.7256394028663635\n",
      "\n",
      "==> Epoch 3/10 Epoch Loss 0.01306389644742012\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 4/10  Batch 20/400 \n",
      "Current Batch Loss 0.3807986080646515\n",
      "\n",
      "Epoch 4/10  Batch 40/400 \n",
      "Current Batch Loss 0.5068058967590332\n",
      "\n",
      "Epoch 4/10  Batch 60/400 \n",
      "Current Batch Loss 0.20892363786697388\n",
      "\n",
      "Epoch 4/10  Batch 80/400 \n",
      "Current Batch Loss 0.5276604890823364\n",
      "\n",
      "Epoch 4/10  Batch 100/400 \n",
      "Current Batch Loss 0.2975755035877228\n",
      "\n",
      "Epoch 4/10  Batch 120/400 \n",
      "Current Batch Loss 0.13457010686397552\n",
      "\n",
      "Epoch 4/10  Batch 140/400 \n",
      "Current Batch Loss 0.3512963354587555\n",
      "\n",
      "Epoch 4/10  Batch 160/400 \n",
      "Current Batch Loss 0.37357190251350403\n",
      "\n",
      "Epoch 4/10  Batch 180/400 \n",
      "Current Batch Loss 0.3711128830909729\n",
      "\n",
      "Epoch 4/10  Batch 200/400 \n",
      "Current Batch Loss 0.24342450499534607\n",
      "\n",
      "Epoch 4/10  Batch 220/400 \n",
      "Current Batch Loss 0.26756903529167175\n",
      "\n",
      "Epoch 4/10  Batch 240/400 \n",
      "Current Batch Loss 0.28264275193214417\n",
      "\n",
      "Epoch 4/10  Batch 260/400 \n",
      "Current Batch Loss 0.26440930366516113\n",
      "\n",
      "Epoch 4/10  Batch 280/400 \n",
      "Current Batch Loss 0.23203639686107635\n",
      "\n",
      "Epoch 4/10  Batch 300/400 \n",
      "Current Batch Loss 0.2767309546470642\n",
      "\n",
      "Epoch 4/10  Batch 320/400 \n",
      "Current Batch Loss 0.28684455156326294\n",
      "\n",
      "Epoch 4/10  Batch 340/400 \n",
      "Current Batch Loss 0.3282383382320404\n",
      "\n",
      "Epoch 4/10  Batch 360/400 \n",
      "Current Batch Loss 0.34319305419921875\n",
      "\n",
      "Epoch 4/10  Batch 380/400 \n",
      "Current Batch Loss 0.3091551959514618\n",
      "\n",
      "Epoch 4/10  Batch 400/400 \n",
      "Current Batch Loss 0.41743624210357666\n",
      "\n",
      "==> Epoch 4/10 Epoch Loss 0.01069879624992609\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 5/10  Batch 20/400 \n",
      "Current Batch Loss 0.32469311356544495\n",
      "\n",
      "Epoch 5/10  Batch 40/400 \n",
      "Current Batch Loss 0.2626275420188904\n",
      "\n",
      "Epoch 5/10  Batch 60/400 \n",
      "Current Batch Loss 0.2892364263534546\n",
      "\n",
      "Epoch 5/10  Batch 80/400 \n",
      "Current Batch Loss 0.4654756188392639\n",
      "\n",
      "Epoch 5/10  Batch 100/400 \n",
      "Current Batch Loss 0.14627507328987122\n",
      "\n",
      "Epoch 5/10  Batch 120/400 \n",
      "Current Batch Loss 0.1997361183166504\n",
      "\n",
      "Epoch 5/10  Batch 140/400 \n",
      "Current Batch Loss 0.24912329018115997\n",
      "\n",
      "Epoch 5/10  Batch 160/400 \n",
      "Current Batch Loss 0.24823956191539764\n",
      "\n",
      "Epoch 5/10  Batch 180/400 \n",
      "Current Batch Loss 0.44177109003067017\n",
      "\n",
      "Epoch 5/10  Batch 200/400 \n",
      "Current Batch Loss 0.2873714864253998\n",
      "\n",
      "Epoch 5/10  Batch 220/400 \n",
      "Current Batch Loss 0.3382277488708496\n",
      "\n",
      "Epoch 5/10  Batch 240/400 \n",
      "Current Batch Loss 0.33137521147727966\n",
      "\n",
      "Epoch 5/10  Batch 260/400 \n",
      "Current Batch Loss 0.30750420689582825\n",
      "\n",
      "Epoch 5/10  Batch 280/400 \n",
      "Current Batch Loss 0.33587634563446045\n",
      "\n",
      "Epoch 5/10  Batch 300/400 \n",
      "Current Batch Loss 0.12092199176549911\n",
      "\n",
      "Epoch 5/10  Batch 320/400 \n",
      "Current Batch Loss 0.29502013325691223\n",
      "\n",
      "Epoch 5/10  Batch 340/400 \n",
      "Current Batch Loss 0.24427248537540436\n",
      "\n",
      "Epoch 5/10  Batch 360/400 \n",
      "Current Batch Loss 0.394307404756546\n",
      "\n",
      "Epoch 5/10  Batch 380/400 \n",
      "Current Batch Loss 0.36621546745300293\n",
      "\n",
      "Epoch 5/10  Batch 400/400 \n",
      "Current Batch Loss 0.4265485405921936\n",
      "\n",
      "==> Epoch 5/10 Epoch Loss 0.009409496560692787\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 6/10  Batch 20/400 \n",
      "Current Batch Loss 0.2542365789413452\n",
      "\n",
      "Epoch 6/10  Batch 40/400 \n",
      "Current Batch Loss 0.39218324422836304\n",
      "\n",
      "Epoch 6/10  Batch 60/400 \n",
      "Current Batch Loss 0.3268573582172394\n",
      "\n",
      "Epoch 6/10  Batch 80/400 \n",
      "Current Batch Loss 0.25116363167762756\n",
      "\n",
      "Epoch 6/10  Batch 100/400 \n",
      "Current Batch Loss 0.15290173888206482\n",
      "\n",
      "Epoch 6/10  Batch 120/400 \n",
      "Current Batch Loss 0.25875771045684814\n",
      "\n",
      "Epoch 6/10  Batch 140/400 \n",
      "Current Batch Loss 0.3689243793487549\n",
      "\n",
      "Epoch 6/10  Batch 160/400 \n",
      "Current Batch Loss 0.24748985469341278\n",
      "\n",
      "Epoch 6/10  Batch 180/400 \n",
      "Current Batch Loss 0.13813138008117676\n",
      "\n",
      "Epoch 6/10  Batch 200/400 \n",
      "Current Batch Loss 0.1308266669511795\n",
      "\n",
      "Epoch 6/10  Batch 220/400 \n",
      "Current Batch Loss 0.249828040599823\n",
      "\n",
      "Epoch 6/10  Batch 240/400 \n",
      "Current Batch Loss 0.2595951557159424\n",
      "\n",
      "Epoch 6/10  Batch 260/400 \n",
      "Current Batch Loss 0.2131657898426056\n",
      "\n",
      "Epoch 6/10  Batch 280/400 \n",
      "Current Batch Loss 0.33176344633102417\n",
      "\n",
      "Epoch 6/10  Batch 300/400 \n",
      "Current Batch Loss 0.14731501042842865\n",
      "\n",
      "Epoch 6/10  Batch 320/400 \n",
      "Current Batch Loss 0.4013780355453491\n",
      "\n",
      "Epoch 6/10  Batch 340/400 \n",
      "Current Batch Loss 0.48949727416038513\n",
      "\n",
      "Epoch 6/10  Batch 360/400 \n",
      "Current Batch Loss 0.2279168963432312\n",
      "\n",
      "Epoch 6/10  Batch 380/400 \n",
      "Current Batch Loss 0.09860191494226456\n",
      "\n",
      "Epoch 6/10  Batch 400/400 \n",
      "Current Batch Loss 0.16834205389022827\n",
      "\n",
      "==> Epoch 6/10 Epoch Loss 0.008861738257110119\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 7/10  Batch 20/400 \n",
      "Current Batch Loss 0.1708335280418396\n",
      "\n",
      "Epoch 7/10  Batch 40/400 \n",
      "Current Batch Loss 0.24692317843437195\n",
      "\n",
      "Epoch 7/10  Batch 60/400 \n",
      "Current Batch Loss 0.18454033136367798\n",
      "\n",
      "Epoch 7/10  Batch 80/400 \n",
      "Current Batch Loss 0.1905481368303299\n",
      "\n",
      "Epoch 7/10  Batch 100/400 \n",
      "Current Batch Loss 0.3099794089794159\n",
      "\n",
      "Epoch 7/10  Batch 120/400 \n",
      "Current Batch Loss 0.14759323000907898\n",
      "\n",
      "Epoch 7/10  Batch 140/400 \n",
      "Current Batch Loss 0.3291245102882385\n",
      "\n",
      "Epoch 7/10  Batch 160/400 \n",
      "Current Batch Loss 0.24974220991134644\n",
      "\n",
      "Epoch 7/10  Batch 180/400 \n",
      "Current Batch Loss 0.3911501467227936\n",
      "\n",
      "Epoch 7/10  Batch 200/400 \n",
      "Current Batch Loss 0.23617146909236908\n",
      "\n",
      "Epoch 7/10  Batch 220/400 \n",
      "Current Batch Loss 0.1789250671863556\n",
      "\n",
      "Epoch 7/10  Batch 240/400 \n",
      "Current Batch Loss 0.19550077617168427\n",
      "\n",
      "Epoch 7/10  Batch 260/400 \n",
      "Current Batch Loss 0.24222269654273987\n",
      "\n",
      "Epoch 7/10  Batch 280/400 \n",
      "Current Batch Loss 0.18207839131355286\n",
      "\n",
      "Epoch 7/10  Batch 300/400 \n",
      "Current Batch Loss 0.14509430527687073\n",
      "\n",
      "Epoch 7/10  Batch 320/400 \n",
      "Current Batch Loss 0.11877802014350891\n",
      "\n",
      "Epoch 7/10  Batch 340/400 \n",
      "Current Batch Loss 0.11879045516252518\n",
      "\n",
      "Epoch 7/10  Batch 360/400 \n",
      "Current Batch Loss 0.20865437388420105\n",
      "\n",
      "Epoch 7/10  Batch 380/400 \n",
      "Current Batch Loss 0.21529600024223328\n",
      "\n",
      "Epoch 7/10  Batch 400/400 \n",
      "Current Batch Loss 0.28150367736816406\n",
      "\n",
      "==> Epoch 7/10 Epoch Loss 0.008023125119507313\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 8/10  Batch 20/400 \n",
      "Current Batch Loss 0.13485221564769745\n",
      "\n",
      "Epoch 8/10  Batch 40/400 \n",
      "Current Batch Loss 0.41656044125556946\n",
      "\n",
      "Epoch 8/10  Batch 60/400 \n",
      "Current Batch Loss 0.13724073767662048\n",
      "\n",
      "Epoch 8/10  Batch 80/400 \n",
      "Current Batch Loss 0.10496354103088379\n",
      "\n",
      "Epoch 8/10  Batch 100/400 \n",
      "Current Batch Loss 0.2743365168571472\n",
      "\n",
      "Epoch 8/10  Batch 120/400 \n",
      "Current Batch Loss 0.2849160134792328\n",
      "\n",
      "Epoch 8/10  Batch 140/400 \n",
      "Current Batch Loss 0.24490855634212494\n",
      "\n",
      "Epoch 8/10  Batch 160/400 \n",
      "Current Batch Loss 0.4611658453941345\n",
      "\n",
      "Epoch 8/10  Batch 180/400 \n",
      "Current Batch Loss 0.32394880056381226\n",
      "\n",
      "Epoch 8/10  Batch 200/400 \n",
      "Current Batch Loss 0.258583664894104\n",
      "\n",
      "Epoch 8/10  Batch 220/400 \n",
      "Current Batch Loss 0.46207231283187866\n",
      "\n",
      "Epoch 8/10  Batch 240/400 \n",
      "Current Batch Loss 0.1555192917585373\n",
      "\n",
      "Epoch 8/10  Batch 260/400 \n",
      "Current Batch Loss 0.21251381933689117\n",
      "\n",
      "Epoch 8/10  Batch 280/400 \n",
      "Current Batch Loss 0.1781524121761322\n",
      "\n",
      "Epoch 8/10  Batch 300/400 \n",
      "Current Batch Loss 0.16845166683197021\n",
      "\n",
      "Epoch 8/10  Batch 320/400 \n",
      "Current Batch Loss 0.2501237988471985\n",
      "\n",
      "Epoch 8/10  Batch 340/400 \n",
      "Current Batch Loss 0.13368014991283417\n",
      "\n",
      "Epoch 8/10  Batch 360/400 \n",
      "Current Batch Loss 0.3933730721473694\n",
      "\n",
      "Epoch 8/10  Batch 380/400 \n",
      "Current Batch Loss 0.2231629341840744\n",
      "\n",
      "Epoch 8/10  Batch 400/400 \n",
      "Current Batch Loss 0.23423990607261658\n",
      "\n",
      "==> Epoch 8/10 Epoch Loss 0.007646999321877956\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 9/10  Batch 20/400 \n",
      "Current Batch Loss 0.36119556427001953\n",
      "\n",
      "Epoch 9/10  Batch 40/400 \n",
      "Current Batch Loss 0.45553141832351685\n",
      "\n",
      "Epoch 9/10  Batch 60/400 \n",
      "Current Batch Loss 0.18905115127563477\n",
      "\n",
      "Epoch 9/10  Batch 80/400 \n",
      "Current Batch Loss 0.37929126620292664\n",
      "\n",
      "Epoch 9/10  Batch 100/400 \n",
      "Current Batch Loss 0.14005446434020996\n",
      "\n",
      "Epoch 9/10  Batch 120/400 \n",
      "Current Batch Loss 0.2835675776004791\n",
      "\n",
      "Epoch 9/10  Batch 140/400 \n",
      "Current Batch Loss 0.09258399903774261\n",
      "\n",
      "Epoch 9/10  Batch 160/400 \n",
      "Current Batch Loss 0.17214958369731903\n",
      "\n",
      "Epoch 9/10  Batch 180/400 \n",
      "Current Batch Loss 0.16645076870918274\n",
      "\n",
      "Epoch 9/10  Batch 200/400 \n",
      "Current Batch Loss 0.2058565765619278\n",
      "\n",
      "Epoch 9/10  Batch 220/400 \n",
      "Current Batch Loss 0.4062058627605438\n",
      "\n",
      "Epoch 9/10  Batch 240/400 \n",
      "Current Batch Loss 0.21391414105892181\n",
      "\n",
      "Epoch 9/10  Batch 260/400 \n",
      "Current Batch Loss 0.17001454532146454\n",
      "\n",
      "Epoch 9/10  Batch 280/400 \n",
      "Current Batch Loss 0.16381031274795532\n",
      "\n",
      "Epoch 9/10  Batch 300/400 \n",
      "Current Batch Loss 0.4187610149383545\n",
      "\n",
      "Epoch 9/10  Batch 320/400 \n",
      "Current Batch Loss 0.11238086223602295\n",
      "\n",
      "Epoch 9/10  Batch 340/400 \n",
      "Current Batch Loss 0.3130798935890198\n",
      "\n",
      "Epoch 9/10  Batch 360/400 \n",
      "Current Batch Loss 0.261018842458725\n",
      "\n",
      "Epoch 9/10  Batch 380/400 \n",
      "Current Batch Loss 0.2682993710041046\n",
      "\n",
      "Epoch 9/10  Batch 400/400 \n",
      "Current Batch Loss 0.151561439037323\n",
      "\n",
      "==> Epoch 9/10 Epoch Loss 0.007421350106596947\n",
      "$$$ Saved a new checkpoint\n",
      "\n",
      "Epoch 10/10  Batch 20/400 \n",
      "Current Batch Loss 0.15130497515201569\n",
      "\n",
      "Epoch 10/10  Batch 40/400 \n",
      "Current Batch Loss 0.14116212725639343\n",
      "\n",
      "Epoch 10/10  Batch 60/400 \n",
      "Current Batch Loss 0.09697512537240982\n",
      "\n",
      "Epoch 10/10  Batch 80/400 \n",
      "Current Batch Loss 0.20507077872753143\n",
      "\n",
      "Epoch 10/10  Batch 100/400 \n",
      "Current Batch Loss 0.39188170433044434\n",
      "\n",
      "Epoch 10/10  Batch 120/400 \n",
      "Current Batch Loss 0.3713235557079315\n",
      "\n",
      "Epoch 10/10  Batch 140/400 \n",
      "Current Batch Loss 0.3621760308742523\n",
      "\n",
      "Epoch 10/10  Batch 160/400 \n",
      "Current Batch Loss 0.1678476333618164\n",
      "\n",
      "Epoch 10/10  Batch 180/400 \n",
      "Current Batch Loss 0.09249335527420044\n",
      "\n",
      "Epoch 10/10  Batch 200/400 \n",
      "Current Batch Loss 0.0798526257276535\n",
      "\n",
      "Epoch 10/10  Batch 220/400 \n",
      "Current Batch Loss 0.3605097830295563\n",
      "\n",
      "Epoch 10/10  Batch 240/400 \n",
      "Current Batch Loss 0.14956746995449066\n",
      "\n",
      "Epoch 10/10  Batch 260/400 \n",
      "Current Batch Loss 0.30222320556640625\n",
      "\n",
      "Epoch 10/10  Batch 280/400 \n",
      "Current Batch Loss 0.27615177631378174\n",
      "\n",
      "Epoch 10/10  Batch 300/400 \n",
      "Current Batch Loss 0.18947146832942963\n",
      "\n",
      "Epoch 10/10  Batch 320/400 \n",
      "Current Batch Loss 0.2959272265434265\n",
      "\n",
      "Epoch 10/10  Batch 340/400 \n",
      "Current Batch Loss 0.38001975417137146\n",
      "\n",
      "Epoch 10/10  Batch 360/400 \n",
      "Current Batch Loss 0.12131543457508087\n",
      "\n",
      "Epoch 10/10  Batch 380/400 \n",
      "Current Batch Loss 0.2685531973838806\n",
      "\n",
      "Epoch 10/10  Batch 400/400 \n",
      "Current Batch Loss 0.23048293590545654\n",
      "\n",
      "==> Epoch 10/10 Epoch Loss 0.0071602994576096535\n",
      "$$$ Saved a new checkpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    running_loss = torch.zeros(1)\n",
    "    \n",
    "    for i_batch, data in enumerate(train_dataloader, 1):\n",
    "        mfcc1, mfcc2, label = data['spec1'], data['spec2'], data['label']\n",
    "        mfcc1 = Variable(mfcc1.float(), requires_grad=True).to(device)\n",
    "        mfcc2 = Variable(mfcc2.float(), requires_grad=True).to(device)\n",
    "        label = Variable(label.float(), requires_grad=True).to(device)\n",
    "                \n",
    "        output1, output2 = model(mfcc1.float(), mfcc2.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output1, output2, label.float())\n",
    "        \n",
    "#         assert mfcc1.dim() == mfcc2.dim() == 4        \n",
    "#         assert output1.dim() == output2.dim() == 2\n",
    "#         assert loss.requires_grad and output1.requires_grad and output2.requires_grad\n",
    "#         assert loss.grad_fn is not None and output1.grad_fn is not None and output2.grad_fn is not None \n",
    "        \n",
    "#         print(\"loss\", loss, loss.requires_grad, loss.grad_fn)\n",
    "#         print(\"output1\", output1.shape, output1.requires_grad, output1.grad_fn, output1.device)\n",
    "#         print(\"output2\", output2.shape, output2.requires_grad, output2.grad_fn, output2.device)\n",
    "\n",
    "        loss.backward()\n",
    "            \n",
    "#         assert mfcc1.requires_grad and mfcc2.requires_grad                \n",
    "#         for name, param in model.named_parameters():\n",
    "#             assert param.requires_grad and param.grad is not None, (name, param.requires_grad, param.grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i_batch % int(n_batches/20) == 0:\n",
    "            print(\"Epoch {}/{}  Batch {}/{} \\nCurrent Batch Loss {}\\n\".format(epoch, N_EPOCHS, i_batch, n_batches, loss.item()))\n",
    "        \n",
    "    epoch_loss = running_loss / len(voxceleb_dataset)\n",
    "    print(\"==> Epoch {}/{} Epoch Loss {}\".format(epoch, N_EPOCHS, epoch_loss.item()))\n",
    "\n",
    "    is_best = epoch_loss < best_loss\n",
    "    if is_best:\n",
    "        best_loss = epoch_loss\n",
    "        \n",
    "        save_checkpoint({'epoch': epoch,\n",
    "                         'state_dict': model.state_dict(),\n",
    "                         'optim_dict': optimizer.state_dict()},\n",
    "                        loss=epoch_loss)\n",
    "    else:\n",
    "        print(\"### Epoch Loss did not improve\\n\")\n",
    "    \n",
    "#     plt.plot(loss_list[50:])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "colab_type": "code",
    "id": "o_8nmcBcIPJw",
    "outputId": "f94a84f1-710b-4d93-af4b-0f887668f53a"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list[5000:])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_Part_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "mlsp",
   "language": "python",
   "name": "mlsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
